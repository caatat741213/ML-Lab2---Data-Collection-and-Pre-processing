{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5445f9e1",
   "metadata": {},
   "source": [
    "## Lab2 - Data Collection and Pre-processing\n",
    "Chao-Chung ,Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdfd5a5",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Primary transactions file: 50000 Sales Records.csv\n",
    "\n",
    "Source: https://excelbianalytics.com/downloads-18-sample-csv-files-data-sets-for-testing-sales/\n",
    "\n",
    "Secondary metadata file: ecommerce_dataset_updated.csv\n",
    "\n",
    "Source: https://www.kaggle.com/datasets/steve1215rogg/e-commerce-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009dd8a0",
   "metadata": {},
   "source": [
    "venv\n",
    "\n",
    "python -m venv lab2venv\n",
    "\n",
    "lab2venv\\Scripts\\activate\n",
    "\n",
    "pip install pandas ipykernel pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb194a1",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step1:Hello, Data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35ed28",
   "metadata": {},
   "source": [
    "### Attribute Identification\n",
    "\n",
    "This step is to identify the attribute types of each field in the dataset. It determines the techniques used for downstream cleaning, transformation, and feature engineering.\n",
    "\n",
    "To identify the attribute types of each field in the dataset. Correctly classifying attributes is the cornerstone of the data engineering lifecycle, as it determines the techniques used for subsequent data cleaning, transformation, and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f237d0",
   "metadata": {},
   "source": [
    "### A: Qualitative Attributes\n",
    "\n",
    "Attributes that represent categories or qualities, without numerical meaning.\n",
    "\n",
    ">Sales Records:\n",
    "\n",
    "Nominal: Region, Country, Item Type, Sales Channel, Order Priority, Order ID.\n",
    "\n",
    ">E-commerce:\n",
    "\n",
    "Nominal: User_ID, Product_ID, Category, Payment_Method\n",
    "\n",
    "### B: Quantitative Attributes\n",
    "\n",
    "Attributes expressed as numbers that can be subjected to mathematical operations.\n",
    "\n",
    ">Sales Records:\n",
    "\n",
    "Interval (Date): Order Date, Ship Date.\n",
    "\n",
    "Ratio (Numerical): Units Sold, Unit Price, Unit Cost, Total Revenue, Total Cost, Total Profit\n",
    "\n",
    ">E-commerce:\n",
    "\n",
    "Interval (Date): Purchase_Date. \n",
    "\n",
    "Ratio (Numerical): Price (Rs.), Discount (%), Final_Price(Rs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9f4c216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sales Records (First 3 rows) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sales Channel",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Order Priority",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Order Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Order ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ship Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Units Sold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unit Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unit Cost",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total Revenue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total Cost",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total Profit",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d7f62fbc-633e-4021-9ea3-458b84778249",
       "rows": [
        [
         "0",
         "Sub-Saharan Africa",
         "Namibia",
         "Household",
         "Offline",
         "M",
         "8/31/2015",
         "897751939",
         "10/12/2015",
         "3604",
         "668.27",
         "502.54",
         "2408445.08",
         "1811154.16",
         "597290.92"
        ],
        [
         "1",
         "Europe",
         "Iceland",
         "Baby Food",
         "Online",
         "H",
         "11/20/2010",
         "599480426",
         "1/9/2011",
         "8435",
         "255.28",
         "159.42",
         "2153286.8",
         "1344707.7",
         "808579.1"
        ],
        [
         "2",
         "Europe",
         "Russia",
         "Meat",
         "Online",
         "L",
         "6/22/2017",
         "538911855",
         "6/25/2017",
         "4848",
         "421.89",
         "364.69",
         "2045322.72",
         "1768017.12",
         "277305.6"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>Sales Channel</th>\n",
       "      <th>Order Priority</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Unit Cost</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Total Cost</th>\n",
       "      <th>Total Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>Household</td>\n",
       "      <td>Offline</td>\n",
       "      <td>M</td>\n",
       "      <td>8/31/2015</td>\n",
       "      <td>897751939</td>\n",
       "      <td>10/12/2015</td>\n",
       "      <td>3604</td>\n",
       "      <td>668.27</td>\n",
       "      <td>502.54</td>\n",
       "      <td>2408445.08</td>\n",
       "      <td>1811154.16</td>\n",
       "      <td>597290.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>Baby Food</td>\n",
       "      <td>Online</td>\n",
       "      <td>H</td>\n",
       "      <td>11/20/2010</td>\n",
       "      <td>599480426</td>\n",
       "      <td>1/9/2011</td>\n",
       "      <td>8435</td>\n",
       "      <td>255.28</td>\n",
       "      <td>159.42</td>\n",
       "      <td>2153286.80</td>\n",
       "      <td>1344707.70</td>\n",
       "      <td>808579.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Online</td>\n",
       "      <td>L</td>\n",
       "      <td>6/22/2017</td>\n",
       "      <td>538911855</td>\n",
       "      <td>6/25/2017</td>\n",
       "      <td>4848</td>\n",
       "      <td>421.89</td>\n",
       "      <td>364.69</td>\n",
       "      <td>2045322.72</td>\n",
       "      <td>1768017.12</td>\n",
       "      <td>277305.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Region  Country  Item Type Sales Channel Order Priority  \\\n",
       "0  Sub-Saharan Africa  Namibia  Household       Offline              M   \n",
       "1              Europe  Iceland  Baby Food        Online              H   \n",
       "2              Europe   Russia       Meat        Online              L   \n",
       "\n",
       "   Order Date   Order ID   Ship Date  Units Sold  Unit Price  Unit Cost  \\\n",
       "0   8/31/2015  897751939  10/12/2015        3604      668.27     502.54   \n",
       "1  11/20/2010  599480426    1/9/2011        8435      255.28     159.42   \n",
       "2   6/22/2017  538911855   6/25/2017        4848      421.89     364.69   \n",
       "\n",
       "   Total Revenue  Total Cost  Total Profit  \n",
       "0     2408445.08  1811154.16     597290.92  \n",
       "1     2153286.80  1344707.70     808579.10  \n",
       "2     2045322.72  1768017.12     277305.60  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- E-commerce Dataset (First 3 rows) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "User_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price (Rs.)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Discount (%)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Final_Price(Rs.)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Payment_Method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Purchase_Date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e2643079-f4c1-48ef-9c87-deff21c6c3e1",
       "rows": [
        [
         "0",
         "337c166f",
         "f414122f-e",
         "Sports",
         "36.53",
         "15",
         "31.05",
         "Net Banking",
         "12-11-2024"
        ],
        [
         "1",
         "d38a19bf",
         "fde50f9c-5",
         "Clothing",
         "232.79",
         "20",
         "186.23",
         "Net Banking",
         "09-02-2024"
        ],
        [
         "2",
         "d7f5f0b0",
         "0d96fc90-3",
         "Sports",
         "317.02",
         "25",
         "237.76",
         "Credit Card",
         "01-09-2024"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Price (Rs.)</th>\n",
       "      <th>Discount (%)</th>\n",
       "      <th>Final_Price(Rs.)</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Purchase_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337c166f</td>\n",
       "      <td>f414122f-e</td>\n",
       "      <td>Sports</td>\n",
       "      <td>36.53</td>\n",
       "      <td>15</td>\n",
       "      <td>31.05</td>\n",
       "      <td>Net Banking</td>\n",
       "      <td>12-11-2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d38a19bf</td>\n",
       "      <td>fde50f9c-5</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>232.79</td>\n",
       "      <td>20</td>\n",
       "      <td>186.23</td>\n",
       "      <td>Net Banking</td>\n",
       "      <td>09-02-2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d7f5f0b0</td>\n",
       "      <td>0d96fc90-3</td>\n",
       "      <td>Sports</td>\n",
       "      <td>317.02</td>\n",
       "      <td>25</td>\n",
       "      <td>237.76</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>01-09-2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_ID  Product_ID  Category  Price (Rs.)  Discount (%)  \\\n",
       "0  337c166f  f414122f-e    Sports        36.53            15   \n",
       "1  d38a19bf  fde50f9c-5  Clothing       232.79            20   \n",
       "2  d7f5f0b0  0d96fc90-3    Sports       317.02            25   \n",
       "\n",
       "   Final_Price(Rs.) Payment_Method Purchase_Date  \n",
       "0             31.05    Net Banking    12-11-2024  \n",
       "1            186.23    Net Banking    09-02-2024  \n",
       "2            237.76    Credit Card    01-09-2024  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Check] Sales Records Row Count: 50000\n",
      "[Check] E-commerce Dataset Row Count: 3660\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# set data\n",
    "# Lab2 - Data Collection and Pre-processing/data/\n",
    "data_dir = 'data'\n",
    "sales_file = os.path.join(data_dir, '50000 Sales Records.csv')\n",
    "ecommerce_file = os.path.join(data_dir, 'ecommerce_dataset_updated.csv')\n",
    "\n",
    "# input Primary:Sales Records\n",
    "df_sales = pd.read_csv(sales_file)\n",
    "\n",
    "# input Secondary:E-commerce Dataset\n",
    "df_ecommerce = pd.read_csv(ecommerce_file)\n",
    "\n",
    "# display First 3 rows\n",
    "print(\"--- Sales Records (First 3 rows) ---\")\n",
    "display(df_sales.head(3))\n",
    "\n",
    "print(\"\\n--- E-commerce Dataset (First 3 rows) ---\")\n",
    "display(df_ecommerce.head(3))\n",
    "\n",
    "# check data >500+ rows\n",
    "print(f\"\\n[Check] Sales Records Row Count: {len(df_sales)}\")\n",
    "print(f\"[Check] E-commerce Dataset Row Count: {len(df_ecommerce)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c201594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: ['Region', 'Country', 'Item Type', 'Sales Channel', 'Order Priority', 'Order Date', 'Order ID', 'Ship Date', 'Units Sold', 'Unit Price', 'Unit Cost', 'Total Revenue', 'Total Cost', 'Total Profit']\n",
      "                          Region      Country        Item Type Sales Channel  \\\n",
      "0             Sub-Saharan Africa      Namibia        Household       Offline   \n",
      "1                         Europe      Iceland        Baby Food        Online   \n",
      "2                         Europe       Russia             Meat        Online   \n",
      "3                         Europe     Moldova              Meat        Online   \n",
      "4                         Europe        Malta           Cereal        Online   \n",
      "5                           Asia    Indonesia             Meat        Online   \n",
      "6             Sub-Saharan Africa     Djibouti        Household        Online   \n",
      "7                         Europe       Greece        Household        Online   \n",
      "8             Sub-Saharan Africa     Cameroon        Cosmetics       Offline   \n",
      "9             Sub-Saharan Africa      Nigeria        Cosmetics        Online   \n",
      "10            Sub-Saharan Africa      Senegal           Fruits       Offline   \n",
      "11  Middle East and North Africa  Afghanistan        Cosmetics       Offline   \n",
      "12                          Asia        India       Vegetables        Online   \n",
      "13  Middle East and North Africa      Lebanon       Vegetables        Online   \n",
      "14  Middle East and North Africa       Turkey  Office Supplies        Online   \n",
      "15  Middle East and North Africa         Iraq        Cosmetics       Offline   \n",
      "16            Sub-Saharan Africa       Rwanda    Personal Care       Offline   \n",
      "17                        Europe      Ukraine        Baby Food       Offline   \n",
      "18                        Europe      Finland  Office Supplies        Online   \n",
      "19            Sub-Saharan Africa  South Sudan        Beverages       Offline   \n",
      "\n",
      "   Order Priority  Order Date   Order ID   Ship Date  Units Sold  Unit Price  \\\n",
      "0               M   8/31/2015  897751939  10/12/2015        3604      668.27   \n",
      "1               H  11/20/2010  599480426    1/9/2011        8435      255.28   \n",
      "2               L   6/22/2017  538911855   6/25/2017        4848      421.89   \n",
      "3               L   2/28/2012  459845054   3/20/2012        7225      421.89   \n",
      "4               M   8/12/2010  626391351   9/13/2010        1975      205.70   \n",
      "5               H   8/20/2010  472974574   8/27/2010        2542      421.89   \n",
      "6               M    2/3/2011  854331052    3/3/2011        4398      668.27   \n",
      "7               L   9/11/2015  895509612   9/26/2015          49      668.27   \n",
      "8               M   1/31/2014  241871583    2/4/2014        4031      437.20   \n",
      "9               C  11/21/2015  409090793   12/7/2015        7911      437.20   \n",
      "10              M   8/29/2016  733153569   10/5/2016        5288        9.33   \n",
      "11              L  10/21/2016  620358741   12/1/2016        6792      437.20   \n",
      "12              C   3/21/2010  897317636    4/5/2010        5084      154.06   \n",
      "13              L  10/15/2010  660954082  11/19/2010        9855      154.06   \n",
      "14              L   10/4/2010  428504407  11/13/2010        2831      651.21   \n",
      "15              M  10/14/2014  787517440  10/19/2014        2766      437.20   \n",
      "16              M   6/15/2013  145854508    7/8/2013         445       81.73   \n",
      "17              M    5/7/2017  581689441   5/29/2017        3687      255.28   \n",
      "18              H   5/21/2015  193508565    7/3/2015        2339      651.21   \n",
      "19              H   6/28/2016  750110709   7/14/2016        3283       47.45   \n",
      "\n",
      "    Unit Cost  Total Revenue  Total Cost  Total Profit  \n",
      "0      502.54     2408445.08  1811154.16     597290.92  \n",
      "1      159.42     2153286.80  1344707.70     808579.10  \n",
      "2      364.69     2045322.72  1768017.12     277305.60  \n",
      "3      364.69     3048155.25  2634885.25     413270.00  \n",
      "4      117.11      406257.50   231292.25     174965.25  \n",
      "5      364.69     1072444.38   927041.98     145402.40  \n",
      "6      502.54     2939051.46  2210170.92     728880.54  \n",
      "7      502.54       32745.23    24624.46       8120.77  \n",
      "8      263.33     1762353.20  1061483.23     700869.97  \n",
      "9      263.33     3458689.20  2083203.63    1375485.57  \n",
      "10       6.92       49337.04    36592.96      12744.08  \n",
      "11     263.33     2969462.40  1788537.36    1180925.04  \n",
      "12      90.93      783241.04   462288.12     320952.92  \n",
      "13      90.93     1518261.30   896115.15     622146.15  \n",
      "14     524.96     1843575.51  1486161.76     357413.75  \n",
      "15     263.33     1209295.20   728370.78     480924.42  \n",
      "16      56.67       36369.85    25218.15      11151.70  \n",
      "17     159.42      941217.36   587781.54     353435.82  \n",
      "18     524.96     1523180.19  1227881.44     295298.75  \n",
      "19      31.79      155778.35   104366.57      51411.78  \n"
     ]
    }
   ],
   "source": [
    "# read the header, print the first 20 lines\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# use nrows to read first 20 rows\n",
    "df = pd.read_csv(sales_file, nrows=20)\n",
    "\n",
    "print(\"Header:\", df.columns.tolist())\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3148412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pandas: Row is a Series ---\n",
      "Region            Sub-Saharan Africa\n",
      "Country                      Namibia\n",
      "Item Type                  Household\n",
      "Sales Channel                Offline\n",
      "Order Priority                     M\n",
      "Order Date                 8/31/2015\n",
      "Order ID                   897751939\n",
      "Ship Date                 10/12/2015\n",
      "Units Sold                      3604\n",
      "Unit Price                    668.27\n",
      "Unit Cost                     502.54\n",
      "Total Revenue             2408445.08\n",
      "Total Cost                1811154.16\n",
      "Total Profit               597290.92\n",
      "Name: 0, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "\n",
      "------------------------------\n",
      "\n",
      "--- CSV Module: Row is a List ---\n",
      "['Sub-Saharan Africa', 'Namibia', 'Household', 'Offline', 'M', '8/31/2015', '897751939', '10/12/2015', '3604', '668.27', '502.54', '2408445.08', '1811154.16', '597290.92']\n",
      "<class 'list'>\n",
      "\n",
      "------------------------------\n",
      "\n",
      "--- Open Slicing: Row is a String ---\n",
      "'Sub-Saharan Africa,Namibia,Household,Offline,M,8/31/2015,897751939,10/12/2015,3604,668.27,502.54,2408445.08,1811154.16,597290.92\\n'\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# open() vs csv vs pandas.read_csv()\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "data_dir = 'data'\n",
    "sales_file = os.path.join(data_dir, '50000 Sales Records.csv')\n",
    "\n",
    "# --- Pandas (One row = Series) ---\n",
    "print(\"--- Pandas: Row is a Series ---\")\n",
    "df = pd.read_csv(sales_file, nrows=1)\n",
    "print(df.iloc[0]) # get first row\n",
    "print(type(df.iloc[0]))\n",
    "\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "\n",
    "# --- CSV Module (One row = List) ---\n",
    "print(\"--- CSV Module: Row is a List ---\")\n",
    "with open(sales_file, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader) # pass header\n",
    "    first_row = next(reader) # get first rowåˆ—\n",
    "    print(first_row)\n",
    "    print(type(first_row))\n",
    "\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "\n",
    "# --- With Open (One row = String) ---\n",
    "print(\"--- Open Slicing: Row is a String ---\")\n",
    "with open(sales_file, 'r', encoding='utf-8') as f:\n",
    "    # use slicing to get specific row\n",
    "    one_row_string = f.readlines()[1] \n",
    "    print(repr(one_row_string)) # repr can see \\n\n",
    "    print(type(one_row_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384d5a4",
   "metadata": {},
   "source": [
    "### Which Python structure best represents one row?\n",
    "\n",
    "\"Pandas\" offers the best visual clarity for data structures; \"csv\" module provides a clean programmatic list; \"open()\" shows raw text strings which are fast to read but messy to look at."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc18bdb",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step2:Pick the Right Container\n",
    "\n",
    "\"Dicts\" offer high flexibility via key-value pairs, \"Namedtuples\" allow attribute-style access but are immutable, and \"Sets\" only store unique, unordered values.\n",
    "However, this lab I use \"Class\" which is superior to all three as it allows encapsulating behavioral methods (like .clean())."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d1fb0",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step3:Implement Functions and Data Structure\n",
    "\n",
    "I instead create a \"Transaction\" class.This allows to encapsulate data with specific behaviors (methods),and must include a .clean() method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea9aa12",
   "metadata": {},
   "source": [
    "Create a Transaction class. This allows data to be encapsulated with specific behaviors (methods). It must include a .clean() method to handle anomalous data and a calculation method (e.g., to calculate profit margin) to meet the experiment's objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c5ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "@dataclass\n",
    "class Transaction:\n",
    "    # Attribute Definitions\n",
    "    order_id: int\n",
    "    item_type: str\n",
    "    order_date: datetime\n",
    "    units_sold: int\n",
    "    unit_price: float\n",
    "    unit_cost: float\n",
    "    total_revenue: float\n",
    "    total_profit: float\n",
    "    category_discount_avg: float = 0.0 # From E-commerce dataset\n",
    "\n",
    "    # Data cleaning method\n",
    "    def clean(self):\n",
    "\n",
    "        # Trim whitespace and handle N/A for item_type\n",
    "        item_str = str(self.item_type).strip().upper()\n",
    "        \n",
    "        if item_str in [\"N/A\", \"NAN\", \"NONE\", \"\"]:\n",
    "            self.item_type = \"Unknown\"\n",
    "        else:\n",
    "            self.item_type = str(self.item_type).strip()\n",
    "\n",
    "        # Set negative profit to 0\n",
    "        if self.total_profit < 0:\n",
    "            self.total_profit = 0.0 \n",
    "            \n",
    "        # Casting to appropriate types\n",
    "        self.total_revenue = float(self.total_revenue)\n",
    "        self.total_profit = float(self.total_profit)\n",
    "    \n",
    "    # --- Step 9: Feature Engineering ---\n",
    "\n",
    "    @property \n",
    "    # Transforms a class method into a \"getter\" for a read-only attribute. It allows methods to be accessed like attributes without needing parentheses.\n",
    "    def profit_per_unit(self) -> float:\n",
    "        # Profit Per Unit\n",
    "        return self.total_profit / self.units_sold if self.units_sold > 0 else 0.0\n",
    "\n",
    "    @property\n",
    "    def efficiency_score(self) -> float:\n",
    "        # Efficiency Score = Profit Per Unit * (1 - Category Average Discount)\n",
    "        return self.profit_per_unit * (1 - self.category_discount_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162a6d0",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step4:Bulk Loaded\n",
    "\n",
    "I uses \"List Comprehension\" to map each row from the Pandas DataFrame by step3.Handling data in bulk rather than individual variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05469e60",
   "metadata": {},
   "source": [
    "Use List Comprehension to convert each column of data in the Pandas DataFrame into the dictionary or object structure defined in Step 3. This is to practice efficiently handling large amounts of data (bulk loading) rather than processing individual variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b9db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 500 objects with joined metadata.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- New: Load Secondary Metadata first ---\n",
    "# Read secondary metadata (E-commerce data) first\n",
    "ecom_df = pd.read_csv('data/ecommerce_dataset_updated.csv')\n",
    "\n",
    "# Group by Category and calculate mean Discount (%)\n",
    "#  { 'Category': avg_discount }\n",
    "category_discount_lookup = ecom_df.groupby('Category')['Discount (%)'].mean().to_dict()\n",
    "\n",
    "def load_primary_data(path: str, limit: int = 500) -> list[Transaction]:\n",
    "\n",
    "    # Input primary data and join with metadata\n",
    "    df = pd.read_csv(path).head(limit)\n",
    "    \n",
    "    transactions = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Perform Join logic, lookup discount based on Item Type\n",
    "        item_type = str(row['Item Type'])\n",
    "        # NAN==> 0.05 (5%)\n",
    "        meta_discount = category_discount_lookup.get(item_type, 5.0) / 100\n",
    "        \n",
    "        tx = Transaction(\n",
    "            order_id=int(row['Order ID']),\n",
    "            item_type=item_type,\n",
    "            order_date=pd.to_datetime(row['Order Date']),\n",
    "            units_sold=int(row['Units Sold']),\n",
    "            unit_price=float(row['Unit Price']),\n",
    "            unit_cost=float(row['Unit Cost']),\n",
    "            total_revenue=float(row['Total Revenue']),\n",
    "            total_profit=float(row['Total Profit']),\n",
    "            category_discount_avg=meta_discount # <-- Join\n",
    "        )\n",
    "        transactions.append(tx)\n",
    "    return transactions\n",
    "\n",
    "# loading\n",
    "sales_list = load_primary_data('data/50000 Sales Records.csv')\n",
    "\n",
    "# Set global variable as the reference point for Step 9\n",
    "DATASET_LAST_DATE = max(t.order_date for t in sales_list)\n",
    "\n",
    "print(f\"Successfully loaded {len(sales_list)} objects with joined metadata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3126acce",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step5:Quick Profiling\n",
    "Python \"Generator expressions\" to perform statistical profiling on the list of Transaction objects,calculating the $min/mean/max$ for revenue and profit. Additionally, we use a Set to determine the count of unique \"Item Types\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a904d4",
   "metadata": {},
   "source": [
    "Use Python's generator expressions to perform statistical profiling on the list of Transaction objects, calculating the $min/mean/max$ for revenue and profit. Additionally, we use a Set to determine the count of unique \"Item Types\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917bba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Quick Profiling Results (N=500) ---\n",
      "Total Profit - Min: $93.99\n",
      "Total Profit - Mean: $398,015.35\n",
      "Total Profit - Max: $1,731,397.46\n",
      "Unique Item Types Count: 12\n",
      "Avg Market Discount (from Metadata): 5.00%\n",
      "List of Unique Types: ['Baby Food', 'Beverages', 'Cereal', 'Clothes', 'Cosmetics', 'Fruits', 'Household', 'Meat', 'Office Supplies', 'Personal Care', 'Snacks', 'Vegetables']\n"
     ]
    }
   ],
   "source": [
    "# Extracting profit data for statistics\n",
    "profits = [tx.total_profit for tx in sales_list]\n",
    "\n",
    "min_profit = min(profits)\n",
    "max_profit = max(profits)\n",
    "mean_profit = sum(profits) / len(profits)\n",
    "\n",
    "# 2. Calculate the number of unique product categories (using \"Set\" , as it automatically filters duplicates)\n",
    "unique_item_types = {tx.item_type for tx in sales_list}\n",
    "item_type_count = len(unique_item_types)\n",
    "avg_meta_discounts = [tx.category_discount_avg for tx in sales_list]\n",
    "\n",
    "# 3. Output results\n",
    "print(f\"--- Quick Profiling Results (N={len(sales_list)}) ---\")\n",
    "print(f\"Total Profit - Min: ${min_profit:,.2f}\")\n",
    "print(f\"Total Profit - Mean: ${mean_profit:,.2f}\")\n",
    "print(f\"Total Profit - Max: ${max_profit:,.2f}\")\n",
    "print(f\"Unique Item Types Count: {item_type_count}\")\n",
    "print(f\"Avg Market Discount (from Metadata): {sum(avg_meta_discounts)/len(avg_meta_discounts):.2%}\")\n",
    "print(f\"List of Unique Types: {sorted(list(unique_item_types))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10083bf",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step 6: Spot the Grime\n",
    "\"Garbage In, Garbage Out\"!!Identifies at least three cases of anomalies (Grime),I will pick a few objects and change their total_profit to negative values or set specific fields to \"N/A\" strings. This directly follows the lab requirement to \"Step 7:Spotting the Grime\".And use Boolean masks find the Grime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5cd55c",
   "metadata": {},
   "source": [
    "Randomly select a few objects and change their total_profit to negative values or set certain fields to \"N/A\" strings. This corresponds to the lab requirement of \"manually injecting dirty data\" and then using Boolean masks to locate the dirty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "817b48ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spotting the Grime Complete 10, 50, and 100.\n",
      "Found Grime Results\n",
      "Negative Profit Cases Found: 2\n",
      " > Order ID: 733153569, Profit: -500.0\n",
      " > Order ID: 553483331, Profit: -9999.0\n",
      "\n",
      "'N/A' Item Type Cases Found: 1\n",
      "Total grime: 3\n"
     ]
    }
   ],
   "source": [
    "# Spotting the Grime\n",
    "\n",
    "import random\n",
    "\n",
    "# Introduce grime data for testing\n",
    "sales_list[10].total_profit = -500.0\n",
    "sales_list[50].item_type = \"N/A\"\n",
    "sales_list[100].total_profit = -9999.0\n",
    "\n",
    "print(\"Spotting the Grime Complete 10, 50, and 100.\")\n",
    "\n",
    "# Find the Grime Boolean masks\n",
    "# use format [t for t in tx if t.price < 0] [cite: 170]\n",
    "found_grime_negative = [t for t in sales_list if t.total_profit < 0]\n",
    "\n",
    "# find Item Type :\"N/A\" \n",
    "found_grime_na = [t for t in sales_list if t.item_type == \"N/A\"]\n",
    "\n",
    "# results\n",
    "print(f\"Found Grime Results\")\n",
    "print(f\"Negative Profit Cases Found: {len(found_grime_negative)}\")\n",
    "for g in found_grime_negative:\n",
    "    print(f\" > Order ID: {g.order_id}, Profit: {g.total_profit}\")\n",
    "    \n",
    "print(f\"\\n'N/A' Item Type Cases Found: {len(found_grime_na)}\")\n",
    "print(f\"Total grime: {len(found_grime_negative) + len(found_grime_na)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b46492",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step 7: Cleaning Rules\n",
    "This step executes the .clean() method encapsulated within the Transaction class to automatically fix the anomalies identified in Step 6. To verify the cleaning effectiveness, I calculate the count of dirty records \"Before\" and \"After\" execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb75bb",
   "metadata": {},
   "source": [
    "This step executes the .clean() method encapsulated within the Transaction class to automatically fix the anomalies identified in Step 6. To verify the cleaning effectiveness, I calculate the count of dirty records \"Before\" and \"After\" execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6733e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Before Cleaning ===\n",
      "Negative Profit count: 2\n",
      " 'N/A' Item Type count: 1\n",
      "\n",
      "=== After Cleaning ===\n",
      "Negative Profit count: 0\n",
      " 'N/A' Item Type count: 0\n",
      "\n",
      "Verified Example (Index 50): Profit is now Unknown\n"
     ]
    }
   ],
   "source": [
    "# --- Before Counts ---\n",
    "before_negative = [t for t in sales_list if t.total_profit < 0]\n",
    "before_na = [t for t in sales_list if t.item_type == \"N/A\"]\n",
    "\n",
    "print(f\"=== Before Cleaning ===\")\n",
    "print(f\"Negative Profit count: {len(before_negative)}\")\n",
    "print(f\" 'N/A' Item Type count: {len(before_na)}\")\n",
    "\n",
    "# --- Execute fixes inside .clean() ---\n",
    "for tx in sales_list:\n",
    "    tx.clean()\n",
    "\n",
    "after_negative = [t for t in sales_list if t.total_profit < 0]\n",
    "after_na = [t for t in sales_list if t.item_type == \"N/A\"]\n",
    "\n",
    "print(f\"\\n=== After Cleaning ===\")\n",
    "print(f\"Negative Profit count: {len(after_negative)}\")\n",
    "print(f\" 'N/A' Item Type count: {len(after_na)}\")\n",
    "\n",
    "# Verified Example\n",
    "print(f\"\\nVerified Example (Index 50): Profit is now {sales_list[50].item_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d64df6",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step 8: Transformations\n",
    "use Python's \"re: module,Transform raw text into computable features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37c2c5",
   "metadata": {},
   "source": [
    "Use Python's re module to extract numerical values from text, transforming raw text into computable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d66bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Regex Extraction Test ---\n",
      "Code: SAVE15     -> Discount: 0.15\n",
      "Code: PROMO20    -> Discount: 0.20\n",
      "Code: WINTER10   -> Discount: 0.10\n",
      "Code: N/A        -> Discount: 0.00\n",
      "Order 897751939: Extracted 0.15 from 'SAVE15'\n",
      "Order 599480426: Extracted 0.15 from 'SAVE15'\n",
      "Order 538911855: Extracted 0.15 from 'SAVE15'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_discount_from_code(code_text):\n",
    "\n",
    "    # \"SAVE15\" -> 0.15, \"OFF20\" -> 0.20\n",
    "    if not isinstance(code_text, str):\n",
    "        return 0.0\n",
    "    \n",
    "    # Use regex to extract digits from the string\n",
    "    match = re.search(r'(\\d+)', code_text)\n",
    "    \n",
    "    if match:\n",
    "        # Convert the extracted digits to a percentage\n",
    "        return float(match.group(1)) / 100\n",
    "    return 0.0\n",
    "\n",
    "# Test the function\n",
    "# Example discount codes and their expected outputs\n",
    "# \"SAVE15\" -> 15% discount, \"PROMO20\" -> 20% discount\n",
    "\n",
    "print(\"--- Regex Extraction Test ---\")\n",
    "test_codes = [\"SAVE15\", \"PROMO20\", \"WINTER10\", \"N/A\"]\n",
    "for code in test_codes:\n",
    "    discount = extract_discount_from_code(code)\n",
    "    print(f\"Code: {code:10} -> Discount: {discount:.2f}\")\n",
    "\n",
    "# Apply the function to the first three transactions in the sales list\n",
    "for tx in sales_list[:3]:\n",
    "    mock_coupon = \"SAVE15\"  # Example coupon code\n",
    "    tx.discount_pct = extract_discount_from_code(mock_coupon)  # Add the extracted discount as a new attribute\n",
    "    print(f\"Order {tx.order_id}: Extracted {tx.discount_pct} from '{mock_coupon}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520901f7",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step 9: Feature Engineering\n",
    "In this step, new features are derived from existing fields.used in downstream analytics and machine learning tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eab11b",
   "metadata": {},
   "source": [
    "Extract new features from existing fields. These engineered features provide additional analytical value and are commonly used in downstream analytics and machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a472eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order ID   | Item Type       | Profit/Unit  | Eff. Score\n",
      "-------------------------------------------------------\n",
      "897751939  | Household       | $165.73      | 157.44\n",
      "599480426  | Baby Food       | $95.86       | 91.07\n",
      "538911855  | Meat            | $57.20       | 54.34\n",
      "459845054  | Meat            | $57.20       | 54.34\n",
      "626391351  | Cereal          | $88.59       | 84.16\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Order ID':<10} | {'Item Type':<15} | {'Profit/Unit':<12} | {'Eff. Score'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for tx in sales_list[:5]:\n",
    "    print(f\"{tx.order_id:<10} | {tx.item_type:<15} | ${tx.profit_per_unit:<11.2f} | {tx.efficiency_score:.2f}\")\n",
    "\n",
    "top_category = max(sales_list, key=lambda x: x.efficiency_score).item_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d54f5",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step 10:Mini-Aggregation\n",
    "Presenting the most \"valuable metrics\",like Which products are the most profitable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efe8a58",
   "metadata": {},
   "source": [
    "Present the most valuable metrics, such as identifying which products are the most profitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26538b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Type            | Avg Profit/Unit    | Avg Eff. Score\n",
      "------------------------------------------------------------\n",
      "Cosmetics            | $          173.87 |          165.18\n",
      "Household            | $          165.73 |          157.44\n",
      "Office Supplies      | $          126.25 |          119.94\n",
      "Baby Food            | $           95.86 |           91.07\n",
      "Cereal               | $           88.59 |           84.16\n",
      "Clothes              | $           73.44 |           69.77\n",
      "Vegetables           | $           63.13 |           59.97\n",
      "Meat                 | $           55.87 |           53.08\n",
      "Snacks               | $           55.14 |           52.38\n",
      "Personal Care        | $           25.06 |           23.81\n",
      "\n",
      "ðŸ’¡Strategic Advice:\n",
      "Category:[Cosmetics] ==> This Category demonstrates the highest efficiency. In future budget allocations, priority should be given to this category to maximize ROI.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create containers for metric lists per category\n",
    "category_metrics = defaultdict(lambda: {'unit_profits': [], 'eff_scores': []})\n",
    "\n",
    "# Iterate and collect feature data\n",
    "for tx in sales_list:\n",
    "    category_metrics[tx.item_type]['unit_profits'].append(tx.profit_per_unit)\n",
    "    category_metrics[tx.item_type]['eff_scores'].append(tx.efficiency_score)\n",
    "\n",
    "# Present results (Sorted by Average Efficiency Score)\n",
    "print(f\"{'Item Type':<20} | {'Avg Profit/Unit':<18} | {'Avg Eff. Score'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "final_analysis = []\n",
    "for item, data in category_metrics.items():\n",
    "    avg_unit_profit = sum(data['unit_profits']) / len(data['unit_profits'])\n",
    "    avg_eff_score = sum(data['eff_scores']) / len(data['eff_scores'])\n",
    "    final_analysis.append((item, avg_unit_profit, avg_eff_score))\n",
    "\n",
    "# Descending by Efficiency Score\n",
    "final_analysis.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "for item, apu, aes in final_analysis[:10]: # top 10\n",
    "    print(f\"{item:<20} | ${apu:>16.2f} | {aes:>15.2f}\")\n",
    "\n",
    "# --- Strategic Advice ---\n",
    "top_eff = final_analysis[0][0]\n",
    "print(f\"\\nðŸ’¡Strategic Advice:\")\n",
    "print(f\"Category:[{top_eff}] ==> This Category demonstrates the highest efficiency. In future budget allocations, priority should be given to this category to maximize ROI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc2dcf",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step 11:Serialization Checkpoint\n",
    "Save cleaned data to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1fe709e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully saved to  data/processed_sales_results.json! (total 500 data points)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def save_to_json(data_list, filename):\n",
    "    json_ready_data = []\n",
    "    \n",
    "    for tx in data_list:\n",
    "        # Convert object to dict and handle non-serializable fields\n",
    "        record = {\n",
    "            \"order_id\": tx.order_id,\n",
    "            \"item_type\": tx.item_type,\n",
    "            \"order_date\": tx.order_date.strftime('%Y-%m-%d'), # date to string\n",
    "            \"total_revenue\": tx.total_revenue,\n",
    "            \"total_profit\": tx.total_profit,\n",
    "            \"profit_per_unit\": tx.profit_per_unit,      # save new feature 1\n",
    "            \"efficiency_score\": tx.efficiency_score,    # save new feature 2\n",
    "            \"market_discount_avg\": tx.category_discount_avg # save Join data\n",
    "        }\n",
    "        json_ready_data.append(record)\n",
    "\n",
    "    # write to file\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_ready_data, f, indent=4)\n",
    "    \n",
    "    print(f\"âœ… Successfully saved to  {filename}! (total {len(json_ready_data)} data points)\")\n",
    "\n",
    "# save file\n",
    "save_to_json(sales_list, 'data/processed_sales_results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed15394",
   "metadata": {},
   "source": [
    "## ðŸŒ•Step 12: Soft Interview Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528c4aa",
   "metadata": {},
   "source": [
    "Functions and OOP transformed chaotic data processing into reusable, modular components. By encapsulating logic for cleaning, metadata joining, and feature engineering, I enhanced code readability and ensured consistency across the data pipeline. This modularity allows me to pivot quickly from raw data handling to high-level strategic analysis(such as evaluating profit efficiency)\n",
    "\n",
    "Separate data processing (Engineering) from business insights (Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4b824",
   "metadata": {},
   "source": [
    "## ðŸŒ•Data-Dictionary Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5406de9",
   "metadata": {},
   "source": [
    "This section integrates field definitions from the **Primary Sales Records** and the **Secondary E-commerce Metadata**, including newly engineered features.\n",
    "\n",
    "| Field | Type | Description | Source | Creation Logic |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| `order_id` | `int` | Unique identifier for each transaction. | Primary CSV | Original field. |\n",
    "| `item_type` | `str` | Product category name. | Primary CSV | Cleaned: Trimmed and N/A/Empty handled as \"Unknown\". |\n",
    "| `order_date` | `datetime` | Date the order was placed. | Primary CSV | Casting: Converted from String to Datetime object. |\n",
    "| `total_profit` | `float` | Net profit generated from the sale. | Primary CSV | Cleaned: Negative values normalized to 0.0. |\n",
    "| `category_discount_avg` | `float` | Average market discount rate for the category. | Secondary Meta | **Join & Mean**: Grouped by Category from E-commerce data. |\n",
    "| `profit_per_unit` | `float` | Profit contribution of a single unit. | Synthetic | **Calculated**: `total_profit / units_sold`. |\n",
    "| `efficiency_score` | `float` | Profitability strength adjusted for market discount. | Combination | **Combination**: `profit_per_unit * (1 - category_discount_avg)`. |\n",
    "\n",
    "### Logic Definitions:\n",
    "1. **Join**: Merged secondary market trends with primary sales records using `Item Type` as the key.\n",
    "2. **Synthetic**: Engineered to evaluate unit-level performance, removing the bias of total sales volume.\n",
    "3. **Combination**: A strategic metric combining internal performance with external market competitiveness to guide budget allocation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab2venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
